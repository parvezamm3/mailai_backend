import json
import time
import requests
import base64
import asyncio
import threading
from bs4 import BeautifulSoup
 # Assuming this is your central message collection
from database import inbox_messages_collection, inbox_conversations_collection
from utils.gemini_utils import call_gemini_api, call_gemini_api_structured
# from celery import Celery, shared_task
from app import celery_app
from utils.attachment_processing import extract_text_from_attachment
# import app

# celery_app will be set dynamically from app.py
# celery_app = None
# Task 1: Generate Importance Score and Description

GEMINI_RESPONSE_SCHEMA = {
    "type": "OBJECT",
    "properties": {
        "summary": {"type": "STRING"},
        "replies": {
            "type": "ARRAY",
            "items": {
                "type": "OBJECT",
                "properties": {
                    "type": {"type": "STRING", "enum": ["Concise", "Confirm", "Polite"]},
                    "text": {"type": "STRING"}
                },
                "required": ["type", "text"]
            }
        },
        "category": {
            "type": "STRING",
            "enum": ["ã‚¨ãƒ©ãƒ¼", "ä¿®ç†", "å•ã„åˆã‚ã›", "å ±å‘Š", "ã‚­ãƒ£ãƒ³ãƒšãƒ¼ãƒ³", "ãƒ—ãƒ­ãƒ¢ãƒ¼ã‚·ãƒ§ãƒ³", "ã‚¹ãƒ‘ãƒ ", "æœ‰å®³", "è¿”ä¿¡ä¸è¦"]
        }
    },
    "required": ["summary", "replies", "category"]
}

GEMINI_RESPONSE_SCHEMA_IAS = {
    "type": "OBJECT",
    "properties": {
        "is_spam": {"type": "boolean"},
        "is_mallicious": {"type": "boolean"},
        "importance": {
            "type": "OBJECT",
            "properties": {
                "score": {"type": "number"},
                "description": {"type": "string"}
            },
            "required": ["score", "description"]
        }
    },
    "required": ["is_spam", "is_mallicious", "importance"]
}

CONDITION_RULES = {
    "severity_rules": {
        "ğŸ”´ é‡å¤§ï¼ˆã‚¯ãƒªãƒ†ã‚£ã‚«ãƒ«ï¼‰ - å³åº§ã«å¯¾å¿œï¼ˆ15åˆ†ä»¥å†…ï¼‰": {
            "ã‚¹ã‚³ã‚¢": "80-100",
            "ã‚·ã‚¹ãƒ†ãƒ å½±éŸ¿": "è³¼è²·ãƒ»èª¿é”æ¥­å‹™ã®å®Œå…¨åœæ­¢ã€ã‚µãƒ—ãƒ©ã‚¤ãƒã‚§ãƒ¼ãƒ³æ–­çµ¶",
            "çŠ¶æ³": {
                "è³¼è²·ç®¡ç†ã‚·ã‚¹ãƒ†ãƒ ": [
                    "ç™ºæ³¨ã‚·ã‚¹ãƒ†ãƒ å…¨åœæ­¢",
                    "ä»•å…¥å…ˆãƒã‚¹ã‚¿å…¨ä»¶ã‚¢ã‚¯ã‚»ã‚¹ä¸å¯",
                    "æ‰¿èªãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼å®Œå…¨åœæ­¢",
                    "åœ¨åº«åˆ‡ã‚Œå•†å“ã®ç·Šæ€¥ç™ºæ³¨ä¸å¯",
                    "æœˆæœ«ç· ã‚å‡¦ç†ã®å®Œå…¨åœæ­¢"
                ],
                "EDIã‚·ã‚¹ãƒ†ãƒ ": [
                    "EDIé€šä¿¡ã®å®Œå…¨æ–­çµ¶ï¼ˆå…¨å–å¼•å…ˆï¼‰",
                    "å—ç™ºæ³¨ãƒ‡ãƒ¼ã‚¿ã®é€å—ä¿¡åœæ­¢",
                    "å¤§æ‰‹å–å¼•å…ˆã¨ã®è‡ªå‹•é€£æºåœæ­¢",
                    "å‡ºè·æŒ‡ç¤ºãƒ‡ãƒ¼ã‚¿é€ä¿¡ä¸å¯",
                    "è«‹æ±‚ãƒ»æ”¯æ‰•ãƒ‡ãƒ¼ã‚¿äº¤æ›åœæ­¢"
                ]
            },
            "æ¥­å‹™ã¸ã®å½±éŸ¿": [
                "ç”Ÿç”£ãƒ©ã‚¤ãƒ³åœæ­¢ãƒªã‚¹ã‚¯",
                "åº—èˆ—ãƒ»å€‰åº«ã¸ã®å•†å“ä¾›çµ¦åœæ­¢",
                "ä¸»è¦å–å¼•å…ˆã¨ã®å–å¼•åœæ­¢",
                "æ±ºæ¸ˆãƒ»æ”¯æ‰•å‡¦ç†ã®å…¨é¢åœæ­¢"
            ],
            "ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰": "ã€ŒEDIåœæ­¢ã€ã€Œç™ºæ³¨ã§ããªã„ï¼ˆå…¨ç¤¾ï¼‰ã€ã€Œå–å¼•å…ˆã¨ç¹‹ãŒã‚‰ãªã„ã€ã€Œç”Ÿç”£åœæ­¢ã€ã€Œåœ¨åº«åˆ‡ã‚Œç·Šæ€¥ã€"
        },
        "ğŸŸ¡ é«˜ï¼ˆé«˜å„ªå…ˆåº¦ï¼‰ - å„ªå…ˆå¯¾å¿œï¼ˆ1æ™‚é–“ä»¥å†…ï¼‰": {
            "ã‚¹ã‚³ã‚¢": "60-79",
            "ã‚·ã‚¹ãƒ†ãƒ å½±éŸ¿": "é‡è¦æ©Ÿèƒ½ã®éƒ¨åˆ†åœæ­¢ã€ä¸»è¦å–å¼•å…ˆã¸ã®å½±éŸ¿",
            "çŠ¶æ³": {
                "è³¼è²·ç®¡ç†ã‚·ã‚¹ãƒ†ãƒ ": [
                    "ç‰¹å®šã‚«ãƒ†ã‚´ãƒªã®ç™ºæ³¨æ©Ÿèƒ½åœæ­¢",
                    "æ‰¿èªè€…ä¸åœ¨ã«ã‚ˆã‚‹æ‰¿èªé…å»¶",
                    "ç™ºæ³¨æ›¸å°åˆ·ãƒ»é€ä»˜æ©Ÿèƒ½ä¸å…·åˆ",
                    "ä»•å…¥å…ˆåˆ¥ç™ºæ³¨ãƒ‡ãƒ¼ã‚¿æŠ½å‡ºä¸å¯",
                    "äºˆç®—ç®¡ç†æ©Ÿèƒ½ã®ç•°å¸¸"
                ],
                "EDIã‚·ã‚¹ãƒ†ãƒ ": [
                    "ç‰¹å®šå–å¼•å…ˆã¨ã®EDIé€šä¿¡éšœå®³",
                    "ãƒ‡ãƒ¼ã‚¿å¤‰æ›ã‚¨ãƒ©ãƒ¼ï¼ˆä¸€éƒ¨å–å¼•å…ˆï¼‰",
                    "è‡ªå‹•ç™ºæ³¨ã®éƒ¨åˆ†çš„åœæ­¢",
                    "åœ¨åº«é€£æºãƒ‡ãƒ¼ã‚¿ã®é€ä¿¡é…å»¶",
                    "å—æ³¨ç¢ºèªãƒ‡ãƒ¼ã‚¿ã®æœªå—ä¿¡"
                ]
            },
            "æ¥­å‹™ã‚·ãƒŠãƒªã‚ª": [
                "ä¸»è¦ä»•å…¥å…ˆã¨ã®å®šæœŸç™ºæ³¨ã«æ”¯éšœ",
                "ç‰¹å®šå•†å“ã‚«ãƒ†ã‚´ãƒªã®èª¿é”åœæ­¢",
                "å¤§å£å–å¼•å…ˆã‹ã‚‰ã®å—æ³¨å‡¦ç†é…å»¶",
                "æœˆæ¬¡ãƒ»é€±æ¬¡ã®å®šæœŸç™ºæ³¨ã«å½±éŸ¿"
            ],
            "ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰": "ã€ŒAç¤¾ã¨ã®EDIä¸é€šã€ã€Œâ—‹â—‹ã‚«ãƒ†ã‚´ãƒªç™ºæ³¨ä¸å¯ã€ã€Œå®šæœŸç™ºæ³¨ã‚¨ãƒ©ãƒ¼ã€ã€Œå—æ³¨ãƒ‡ãƒ¼ã‚¿æœªç€ã€"
        },
        "ğŸŸ¢ ä¸­ï¼ˆæ¨™æº–ï¼‰ - é€šå¸¸å¯¾å¿œï¼ˆ4æ™‚é–“ä»¥å†…ï¼‰": {
            "ã‚¹ã‚³ã‚¢": "30-59",
            "ã‚·ã‚¹ãƒ†ãƒ å½±éŸ¿": "å€‹äººãƒ»éƒ¨åˆ†çš„ãªæ¥­å‹™ã¸ã®å½±éŸ¿",
            "çŠ¶æ³": {
                "è³¼è²·ç®¡ç†ã‚·ã‚¹ãƒ†ãƒ ": [
                    "å€‹äººã®ç™ºæ³¨æ¨©é™è¨­å®šå•é¡Œ",
                    "ç‰¹å®šå•†å“ã®å˜ä¾¡ãƒ»ä»•å…¥å…ˆæƒ…å ±æ›´æ–°",
                    "ç™ºæ³¨æ›¸å°åˆ·ãƒ»é€ä»˜æ©Ÿèƒ½ä¸å…·åˆ",
                    "å¸³ç¥¨ãƒ¬ã‚¤ã‚¢ã‚¦ãƒˆã®è»½å¾®ãªå•é¡Œ",
                    "ãƒ¦ãƒ¼ã‚¶ãƒ¼æ“ä½œã«é–¢ã™ã‚‹è³ªå•"
                ],
                "EDIã‚·ã‚¹ãƒ†ãƒ ": [
                    "å°è¦æ¨¡å–å¼•å…ˆã¨ã®é€šä¿¡å•é¡Œ",
                    "ãƒ‡ãƒ¼ã‚¿ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆè»½å¾®ä¿®æ­£",
                    "é€ä¿¡å±¥æ­´ãƒ»ãƒ­ã‚°ç¢ºèªæ–¹æ³•",
                    "EDIè¨­å®šå¤‰æ›´ã®ç›¸è«‡"
                ]
            },
            "ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰": "ã€Œå€‹äººã‚¢ã‚«ã‚¦ãƒ³ãƒˆã€ã€Œæ“ä½œæ–¹æ³•ã€ã€Œå±¥æ­´ç¢ºèªã€ã€Œè»½å¾®ãªä¿®æ­£ã€"
        },
        "ğŸŸ¦ ä½ï¼ˆä¸€èˆ¬ï¼‰ - è¨ˆç”»å¯¾å¿œï¼ˆ1å–¶æ¥­æ—¥ä»¥å†…ï¼‰": {
            "ã‚¹ã‚³ã‚¢": "0-29",
            "ã‚·ã‚¹ãƒ†ãƒ å½±éŸ¿": "æ¥­å‹™ç¶™ç¶šã«ç›´æ¥å½±éŸ¿ãªã—",
            "å†…å®¹": [
                "ã‚·ã‚¹ãƒ†ãƒ æ”¹å–„è¦æœ›",
                "æ–°è¦å–å¼•å…ˆEDIæ¥ç¶šæº–å‚™",
                "ãƒã‚¹ã‚¿ãƒ‡ãƒ¼ã‚¿æ•´å‚™è¨ˆç”»",
                "æ“ä½œç ”ä¿®ãƒ»ãƒãƒ‹ãƒ¥ã‚¢ãƒ«æ•´å‚™",
                "å°†æ¥çš„ãªã‚·ã‚¹ãƒ†ãƒ æ›´æ”¹ç›¸è«‡"
            ]
        }
    }
}

def get_previous_messages(conv_id, email_address, current_message_id, current_message_time):
    """
    Finds and returns all messages in a conversation received before a specific message.
    """
    
    # 1. Define the query to find the specific conversation
    query = {
        'conv_id': conv_id,
        'email_address': email_address
    }
    
    # 2. Define the projection to filter the messages array
    projection = {
        '_id': 0,
        'messages': {
            '$filter': {
                'input': '$messages',
                'as': 'msg',
                'cond': {
                    # Filter for messages with a received_time less than the reference time
                    '$lt': ['$$msg.received_time', current_message_time]
                }
            }
        }
    }
    
    # 3. Find the document and apply the filter
    messages_result = inbox_conversations_collection.aggregate([
        {'$match': query},
        {'$project': projection}
    ])
    
    # 4. Extract the messages and sort them by received_time
    # The $filter operation preserves the original order, but it's good practice to sort explicitly.
    try:
        doc = next(messages_result)
        # print(doc)
        # Sort the filtered messages list in ascending order of received_time
        sorted_messages = sorted(doc.get('messages', []), key=lambda x: x.get('received_time'))
        return sorted_messages
    except StopIteration:
        return []
    

class LoopThread(threading.Thread):
    def __init__(self):
        super().__init__(daemon=True)
        self.loop = asyncio.new_event_loop()
    def run(self):
        asyncio.set_event_loop(self.loop)
        self.loop.run_forever()

_loop_thread = LoopThread()
_loop_thread.start()
time.sleep(0.1)  # Give it time to start

def run_async(coro, timeout=None):
    # print("Running asynchronously")
    future = asyncio.run_coroutine_threadsafe(coro, _loop_thread.loop)
    return future.result(timeout)


async def _extract_text_from_attachments(data, filename, message_type):
    """
    Helper function to extract plain text content from attachments within the
    full_message_payload (either Gmail or Outlook format).
    This is a manual step, assuming attachment data is embedded in the payload.
    For large attachments, a separate API call or FastMCP would be needed.
    """
    attachment_texts = []
    try:
        if 'gmail' in message_type:
            decoded_bytes = base64.urlsafe_b64decode(data)
        elif 'outlook' in message_type:
            decoded_bytes = base64.b64decode(data)
        else:
            return attachment_texts

        # Await the coroutine instead of calling asyncio.run()
        text = await extract_text_from_attachment(decoded_bytes, filename)
        if text:
            attachment_texts.append(f"--- Attachment: {filename} ---\n{text}\n--- End Attachment ---")
    except Exception as e:
        print(f"Error processing attachment {filename}: {e}")
    
    return attachment_texts

# @celery_app.task(name='tasks.generate_attatchment_summary')
async def _generate_attachment_summary_async(conv_id, msg_id, user_id, provider_type):
    # print('Generating summary')
    message_result = inbox_conversations_collection.find_one(
        {
            'conv_id': conv_id,
            'email_address':user_id,
            'messages.message_id': msg_id
        },
        {
            # Projection to include only the messages that match the criteria
            '_id': 0,  # Exclude the _id field
            'messages': {
                '$elemMatch': {
                    'message_id': msg_id
                }
            }
        }
    )
    if not message_result or not message_result.get('messages'):
        # print('Message not found.')
        return 'Message Not Found'
    attachments = message_result['messages'][0].get('attachments', [])
    for attachment in attachments:
        time.sleep(2)
        attachment_size = attachment.get('size')
        if attachment_size<1200000:
            extracted_text =await _extract_text_from_attachments(attachment.get('contentBytes'), attachment.get('name'), provider_type)
            attachment_summary = ""
            if extracted_text:
                prompt_attachment_summary = f'Summarize the content of the attatchments: {extracted_text} within 200 characters in Japanese. Only include Japanese, no Romaji.'
                try:
                    attachment_summary = await call_gemini_api(prompt_attachment_summary,  model="gemini-2.0-flash")
                    inbox_conversations_collection.update_one(
                        {
                            'conv_id': conv_id, 'email_address': user_id, 'messages.message_id':msg_id
                        },
                        {
                            '$set': {
                            'messages.$[message].attachments.$[attachment].attachment_summary': attachment_summary,
                            }
                        },
                        array_filters=[
                            {"message.message_id": msg_id},
                            {"attachment.id": attachment.get('id')}
                        ]
                    )
                except Exception as e:
                    print("Gemini error occured", e)
            else:
                print('Extraction is not completed')
        else:
            print('File is Too Large!!!')
            # return 'Extraction Failed'
    return "Done"


@celery_app.task(name='tasks.generate_attachment_summary')
def generate_attachment_summary(conv_id, msg_id, user_id, provider_type):
    # run the actual async implementation in a fresh event loop
    try:
        result = run_async(_generate_attachment_summary_async(conv_id, msg_id, user_id, provider_type))
        return result
    except Exception as e:
        # Optionally log error, or update DB with failure
        return f'Error: {str(e)}'


async def _generate_previous_emails_summary_async(conv_id, message_id, user_id):
    current_message_doc = inbox_conversations_collection.find_one(
        {'conv_id': conv_id, "email_address":user_id, 'messages.message_id': message_id},
        {'_id': 0, 'messages.$': 1}
    )
    current_message = current_message_doc['messages'][0]
    previous_message_texts = ''
    pm_count = 1
    if current_message_doc and 'messages' in current_message_doc:
        current_time = current_message['received_time']
        previous_messages = get_previous_messages(conv_id, user_id, message_id, current_time)
        
        for pm in previous_messages:
            if isinstance(pm, dict):
                previous_message_texts+=f'Messages {pm_count}: \n{pm.get('body', '')}\n\n'
            pm_count+=1

    prompt_summary = f'Summarize the key points and unresolved issues from this previous email of this thread: {previous_message_texts} within 200 characters in Japanese. Only include Japanese, no Romaji.'

    try:
        # time.sleep(2)
        summary = ""
        if previous_message_texts:
            summary = await call_gemini_api(prompt_summary)
        inbox_conversations_collection.update_one(
            {
                'conv_id': conv_id, 'email_address': user_id, 'messages.message_id':message_id
            },
            {
                '$set': {
                'messages.$[message].previous_messages_summary': summary,
                }
            },
            array_filters=[
                {"message.message_id": message_id},
            ]
        )
    except Exception as e:
        print("Gemini error occured", e)
        return False

@celery_app.task(name='tasks.generate_previous_emails_summary')
def generate_previous_emails_summary(conv_id, message_id, user_id):
    try:
        result = run_async(_generate_previous_emails_summary_async(conv_id, message_id, user_id))
        return result
    except Exception as e:
        # Optionally log error, or update DB with failure
        return f'Error: {str(e)}'
    

async def _generate_importance_analysis_async(conv_id, message_id, user_id):
    """Celery task to generate importance score and description using Gemini API."""
    print(f"Running Importance Analysis Task Async.")

    current_message_doc = inbox_conversations_collection.find_one(
        {'conv_id': conv_id, 'messages.message_id': message_id},
        {'_id': 0, 'messages.$': 1}
    )
    current_message = current_message_doc['messages'][0]
    sender = current_message.get('sender', 'sender')
    subject = current_message.get('subject', '')
    body = current_message.get('body')
    attachments = current_message.get('attachments', {})
    attachment_summary = f''
    if len(attachments)>0:
        for attachment in attachments:
            attachment_summary+=f"Summary of Attachment Name:{attachment.get('name')} Summary:{attachment.get('attachment_summary', '')}"
    else:
        attachment_summary+="No Attachments"

    previous_emails_summary = current_message.get("previous_messages_summary")
    if not previous_emails_summary:
        previous_emails_summary = "No previous emails"
    formatted_rules = json.dumps(CONDITION_RULES, indent=2, ensure_ascii=False)
    prompt_template = (
        f'Analyze the following email (Sender + Subject + Body + Attachment Summary + Summary from the previous emails of the conversation thread).'
        f'First, check if the mail is spam or has malicious content.'
        f'Then, assign it an urgency score"importance score" from 0 to 100, based on these conditions: {formatted_rules}.'
        f'Provide a one-sentence summary *within 100 characters* describing the reason behind the scoring in Japanese.'
        f'If any keyword or its synonymous text from the conditions exists in the mail, score it corresponding to its category and mention the keyword in the description.'
        f'\n\n'
        f'**Output Format (JSON)**:\n'
        f'{json.dumps(GEMINI_RESPONSE_SCHEMA_IAS, indent=2)}\n\n'
        f'Sender: {sender}\n'
        f'Subject: {subject}\n'
        f'Body:\n{body}\n\n'
        f'Attachment Summary:\n{attachment_summary}\n\n'
        f'Previous Conversation Summary:\n{previous_emails_summary}'
    ) 

    gemini_response = await call_gemini_api_structured(prompt_template, GEMINI_RESPONSE_SCHEMA_IAS, temp=0.8, model="gemini-2.0-flash")

    is_spam = False
    is_malicious = False
    importance_score = 0
    importance_description = "èª¬æ˜ã¯ã‚ã‚Šã¾ã›ã‚“"
    # print(gemini_response)
    if gemini_response:
        try:
            is_spam = gemini_response.get('is_spam', is_spam)
            is_malicious = gemini_response.get('is_malicious', is_malicious)
            importance = gemini_response.get('importance', {})
            importance_score = importance.get('score', importance_score)
            importance_description = importance.get('description', importance_description)

            if importance_score >= 70 and "helpdesk@ffp.co.jp" in current_message.get('receivers', ''):
                received_time = current_message.get('received_time', '')
                teams_payload = {
                    "type": "message",
                    "attachments": [
                        {
                        "contentType": "application/vnd.microsoft.card.adaptive",
                        "content": {
                            "$schema": "http://adaptivecards.io/schemas/adaptive-card.json",
                            "type": "AdaptiveCard",
                            "version": "1.2",
                            "body": [
                                {
                                    "type": "TextBlock",
                                    "text": "Critical Mail Alert",
                                    "wrap": True,
                                    "style": "heading",
                                    "color":"attention"
                                },
                                {
                                    "type": "FactSet",
                                    "facts": [
                                        {
                                        "title": "ä»¶å",
                                        "value": f"{subject}"
                                        },
                                        {
                                        "title": "å—ä¿¡æ—¥æ™‚",
                                        "value": f"{received_time}"
                                        },
                                        {
                                        "title": "æœ¬æ–‡",
                                        "value": f"{body}"
                                        }
                                    ]
                                },
                            ],
                        }
                    }
                    ]
                }

                # Set up the headers for the request
                headers = {
                    "Content-Type": "application/json"
                }
                try:
                    teams_webhook_url = "https://prod-07.japaneast.logic.azure.com:443/workflows/7846e0ca56c44bd7a1b2aeb34ac6a4da/triggers/manual/paths/invoke?api-version=2016-06-01&sp=%2Ftriggers%2Fmanual%2Frun&sv=1.0&sig=-TVc0SuSMCleLgFr2QrR2us-Jbe81poMuU3QhWHbnFo"
                    response = requests.post(teams_webhook_url, data=json.dumps(teams_payload), headers=headers)
                    response.raise_for_status() # Raise an HTTPError for bad responses (4xx or 5xx)
                    print("Message successfully sent to Teams.")
                except requests.exceptions.HTTPError as err:
                    print(f"HTTP Error: {err}")
                except Exception as e:
                    print(f"An error occurred: {e}")

        except Exception as e:
            print(f"Error parsing Gemini importance response for {message_id}: {e}")
            importance_description = f"Failed to parse importance response: {gemini_response}"
            return False

    inbox_conversations_collection.update_one(
        {
            'conv_id': conv_id, 'email_address': user_id, 'messages.message_id':message_id
        },
        {
            '$set': {
            'messages.$[message].analysis.is_spam': is_spam,
            'messages.$[message].analysis.is_malicious': is_malicious,
            'messages.$[message].analysis.importance_score': importance_score,
            'messages.$[message].analysis.importance_description': importance_description,
            }
        },
        array_filters=[
            {"message.message_id": message_id},
        ])

    print(f"Importance analysis for {message_id[:10]} completed: Score={importance_score}, Description='{importance_description[:50]}...'")
    return True

  

@celery_app.task(name='tasks.generate_importance_analysis')
def generate_importance_analysis(conv_id, message_id, user_id):
    """Celery task to generate importance score and description using Gemini API."""
    print(f"Running Importance Analysis Task.")
    try:
        # print(conv_id, message_id, user_id)
        result = run_async(_generate_importance_analysis_async(conv_id, message_id, user_id))
        return 'Done'
    except Exception as e:
        return f'Error: {str(e)}'
    

async def _generate_summary_and_replies_async(conv_id, message_id, user_id):
    """Celery task to generate email summary, three replies, and categorization using Gemini API."""
    print(f"Running summary, replies, and categorization task for message {message_id} (User: {user_id})")
    # message_doc = inbox_messages_collection.find_one({'message_id': message_id, 'email_address': user_id})
    current_message_doc = inbox_conversations_collection.find_one(
        {'conv_id': conv_id, 'messages.message_id': message_id},
        {'_id': 0, 'messages.$': 1}
    )
    current_message = current_message_doc['messages'][0]

    subject = current_message.get('subject', '')
    body = current_message.get('body')
    
    sender = current_message.get('sender', '')
    attachment_summary = current_message.get('attachment_summary', '')
    previous_email_summary = current_message.get('previous_messages_summary', '') # Assuming history_summary is stored in message_doc

    prompt = (
        f"Analyze the following email thread. "
        f"Here is the original email, summary of the attached file and a summary of the previous conversation thread."
        f"Based on the content, perform the following tasks and provide the output in JSON format.\n\n"
        f"1. **Summarize the email**: Provide a concise summary (2-3 sentences) of the latest email and its context within the conversation history."
        f"2. **Suggest Replies**: If a reply is needed, suggest three reply options in Business Japanese."
        f"   These replies should be **from the recipient of this email (the user of this system) to the sender of this email** (`{sender}`). "
        f"   - One 'Concise' reply."
        f"   - One 'Confirm' reply (for confirmation of receipt or understanding)."
        f"   - One 'Polite' reply (using the most polite form of Japanese)."
        f"   - **You must format the replies to be highly readable. Insert newline character (`\n`) with regards to standard Japanese mail to separate sentences or phrases for clarity.**"
        f"   If no reply is needed (e.g., sender contains 'no-reply' or content is purely informational with no action required), the 'replies' array should be empty and the 'summary' should state 'è¿”ä¿¡ä¸è¦' (No reply needed)."
        f"3. **Categorize the email**: Assign the email to one of the following categories in Japanese: "
        f"'ã‚¨ãƒ©ãƒ¼' (Error), 'ä¿®ç†' (Repair), 'å•ã„åˆã‚ã›' (Inquiry), 'å ±å‘Š' (Report), 'ã‚­ãƒ£ãƒ³ãƒšãƒ¼ãƒ³' (Campaign),'ãŠçŸ¥ã‚‰ã›' (Notice), 'ãƒ—ãƒ­ãƒ¢ãƒ¼ã‚·ãƒ§ãƒ³' (Promotion), 'ã‚¹ãƒ‘ãƒ ' (Spam), 'æœ‰å®³' (Harmful), 'è¿”ä¿¡ä¸è¦' (No reply needed)."
        f"\n\n"
        f"**Output Format (JSON)**:\n"
        f"{json.dumps(GEMINI_RESPONSE_SCHEMA, indent=2)}\n\n" # Embed the schema for clarity to the model
        f"Sender: {sender}\n\nSubject: {subject}\n\nBody:\n{body}\n\nAttachment Summary{attachment_summary}\n\nPrevious Conversation Summary:\n{previous_email_summary}"
    )

    # print(prompt)

    gemini_response_json = await call_gemini_api_structured(prompt, GEMINI_RESPONSE_SCHEMA)
    # print(gemini_response_json)
    summary = "Could not generate summary."
    replies = []
    category = "Unknown"
    # print(gemini_response_json)
    if gemini_response_json:
        try:
            summary = gemini_response_json.get('summary', summary)
            replies = [r.get('text') for r in gemini_response_json.get('replies', []) if r.get('text')]
            category = gemini_response_json.get('category', category)

        except Exception as e:
            print(f"Error parsing structured Gemini response for {message_id}: {e}")
            summary = f"Failed to parse structured response: {gemini_response_json}"
            replies = ["Error parsing replies.", "Please check backend logs."]
            category = "Parsing Error"

    inbox_conversations_collection.update_one(
        {
            'conv_id': conv_id, 'email_address': user_id, 'messages.message_id':message_id
        },
        {
            '$set': {
            'messages.$[message].analysis.summary': summary,
            'messages.$[message].analysis.replies': replies,
            'messages.$[message].analysis.category': category,
            }
        },
        array_filters=[
            {"message.message_id": message_id},
        ])
    return True
    
@celery_app.task(name='tasks.generate_summary_and_replies')
def generate_summary_and_replies(conv_id, message_id, user_id):
    """Celery task to generate email summary, three replies, and categorization using Gemini API."""
    # print(f"Running summary, replies, and categorization task for message {message_id} (User: {user_id})")
    try:
        # print(conv_id, message_id, user_id)
        result = run_async(_generate_summary_and_replies_async(conv_id, message_id, user_id))
        return 'Done'
    except Exception as e:
        return f'Error: {str(e)}'
    
